{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym[all] in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (6.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (0.0.8)\n",
      "Requirement already satisfied: opencv-python>=3.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (4.8.1.78)\n",
      "Requirement already satisfied: mujoco==2.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.2.0)\n",
      "Requirement already satisfied: ale-py~=0.8.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (0.8.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (3.8.0)\n",
      "Requirement already satisfied: pygame==2.1.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.1.0)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.3.5)\n",
      "Requirement already satisfied: moviepy>=1.0.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (1.0.3)\n",
      "Requirement already satisfied: mujoco-py<2.2,>=2.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.1.2.14)\n",
      "Requirement already satisfied: pytest==7.0.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (7.0.1)\n",
      "Requirement already satisfied: swig==4.* in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (4.1.1)\n",
      "Requirement already satisfied: imageio>=2.14.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (2.31.5)\n",
      "Requirement already satisfied: lz4>=3.1.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from gym[all]) (4.3.2)\n",
      "Requirement already satisfied: pyopengl in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco==2.2->gym[all]) (3.1.7)\n",
      "Requirement already satisfied: absl-py in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco==2.2->gym[all]) (2.0.0)\n",
      "Requirement already satisfied: glfw in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco==2.2->gym[all]) (2.6.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (22.2.0)\n",
      "Requirement already satisfied: packaging in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (23.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (2.0.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (1.11.0)\n",
      "Requirement already satisfied: iniconfig in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from pytest==7.0.1->gym[all]) (2.0.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from ale-py~=0.8.0->gym[all]) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from ale-py~=0.8.0->gym[all]) (4.8.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from imageio>=2.14.1->gym[all]) (10.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.8.0->gym[all]) (3.13.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (4.43.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.0->gym[all]) (0.12.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from moviepy>=1.0.0->gym[all]) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from moviepy>=1.0.0->gym[all]) (0.1.10)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from moviepy>=1.0.0->gym[all]) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from moviepy>=1.0.0->gym[all]) (4.66.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from moviepy>=1.0.0->gym[all]) (0.4.9)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from imageio-ffmpeg>=0.2.0->moviepy>=1.0.0->gym[all]) (58.0.4)\n",
      "Requirement already satisfied: fasteners~=0.15 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco-py<2.2,>=2.1->gym[all]) (0.19)\n",
      "Requirement already satisfied: cffi>=1.10 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco-py<2.2,>=2.1->gym[all]) (1.15.1)\n",
      "Requirement already satisfied: Cython>=0.27.2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from mujoco-py<2.2,>=2.1->gym[all]) (3.0.3)\n",
      "Requirement already satisfied: pycparser in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1->gym[all]) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->gym[all]) (1.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gym[all]) (2.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gym[all]) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gym[all]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gym[all]) (2023.7.22)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (1.24.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp39-none-macosx_11_0_arm64.whl (59.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 59.5 MB 309 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from torch) (4.8.0)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 120 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[K     |████████████████████████████████| 173 kB 137 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sympy in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/michaeltomadakis/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: networkx, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.12.4 fsspec-2023.9.2 networkx-3.1 torch-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install 'gym[all]'\n",
    "!{sys.executable} -m pip install 'numpy'\n",
    "!{sys.executable} -m pip install 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    %pip install pyvirtualdisplay\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(600, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer_uniform(layer: nn.Linear, init_w: float = 3e-3) -> nn.Linear:\n",
    "    \"\"\"Init uniform parameters on the single layer.\"\"\"\n",
    "    layer.weight.data.uniform_(-init_w, init_w)\n",
    "    layer.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    return layer\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        log_std_min: int = -20,\n",
    "        log_std_max: int = 0,\n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        self.hidden = nn.Linear(in_dim, 32)\n",
    "\n",
    "        self.mu_layer = nn.Linear(32, out_dim)\n",
    "        self.mu_layer = init_layer_uniform(self.mu_layer)\n",
    "\n",
    "        self.log_std_layer = nn.Linear(32, out_dim)\n",
    "        self.log_std_layer = init_layer_uniform(self.log_std_layer)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = F.relu(self.hidden(state))\n",
    "        \n",
    "        mu = torch.tanh(self.mu_layer(x))\n",
    "        log_std = torch.tanh(self.log_std_layer(x))\n",
    "        log_std = self.log_std_min + 0.5 * (\n",
    "            self.log_std_max - self.log_std_min\n",
    "        ) * (log_std + 1)\n",
    "        std = torch.exp(log_std)\n",
    "\n",
    "        dist = Normal(mu, std)\n",
    "        action = dist.sample()\n",
    "\n",
    "        return action, dist\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(in_dim, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.out = init_layer_uniform(self.out)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = F.relu(self.hidden(state))\n",
    "        value = self.out(x)\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(\n",
    "    next_value: list, \n",
    "    rewards: list, \n",
    "    masks: list, \n",
    "    values: list, \n",
    "    gamma: float, \n",
    "    tau: float\n",
    ") -> List:\n",
    "    \"\"\"Compute gae.\"\"\"\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns: Deque[float] = deque()\n",
    "\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = (\n",
    "            rewards[step]\n",
    "            + gamma * values[step + 1] * masks[step]\n",
    "            - values[step]\n",
    "        )\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.appendleft(gae + values[step])\n",
    "\n",
    "    return list(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(\n",
    "    epoch: int,\n",
    "    mini_batch_size: int,\n",
    "    states: torch.Tensor,\n",
    "    actions: torch.Tensor,\n",
    "    values: torch.Tensor,\n",
    "    log_probs: torch.Tensor,\n",
    "    returns: torch.Tensor,\n",
    "    advantages: torch.Tensor,\n",
    "):\n",
    "    \"\"\"Yield mini-batches.\"\"\"\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(epoch):\n",
    "        for _ in range(batch_size // mini_batch_size):\n",
    "            rand_ids = np.random.choice(batch_size, mini_batch_size)\n",
    "            yield states[rand_ids, :], actions[rand_ids], values[\n",
    "                rand_ids\n",
    "            ], log_probs[rand_ids], returns[rand_ids], advantages[rand_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent:\n",
    "    \"\"\"PPO Agent.\n",
    "    Attributes:\n",
    "        env (gym.Env): Gym env for training\n",
    "        gamma (float): discount factor\n",
    "        tau (float): lambda of generalized advantage estimation (GAE)\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): amount of clipping surrogate objective\n",
    "        epoch (int): the number of update\n",
    "        rollout_len (int): the number of rollout\n",
    "        entropy_weight (float): rate of weighting entropy into the loss function\n",
    "        actor (nn.Module): target actor model to select actions\n",
    "        critic (nn.Module): critic model to predict state values\n",
    "        transition (list): temporory storage for the recent transition\n",
    "        device (torch.device): cpu / gpu\n",
    "        total_step (int): total step numbers\n",
    "        is_test (bool): flag to show the current mode (train / test)        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        batch_size: int,\n",
    "        gamma: float,\n",
    "        tau: float,\n",
    "        epsilon: float,\n",
    "        epoch: int,\n",
    "        rollout_len: int,\n",
    "        entropy_weight: float,\n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon\n",
    "        self.epoch = epoch\n",
    "        self.rollout_len = rollout_len\n",
    "        self.entropy_weight = entropy_weight\n",
    "\n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.shape[0]\n",
    "        self.actor = Actor(obs_dim, action_dim).to(self.device)\n",
    "        self.critic = Critic(obs_dim).to(self.device)\n",
    "\n",
    "        # optimizer\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=0.001)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=0.005)\n",
    "\n",
    "        # memory for training\n",
    "        self.states: List[torch.Tensor] = []\n",
    "        self.actions: List[torch.Tensor] = []\n",
    "        self.rewards: List[torch.Tensor] = []\n",
    "        self.values: List[torch.Tensor] = []\n",
    "        self.masks: List[torch.Tensor] = []\n",
    "        self.log_probs: List[torch.Tensor] = []\n",
    "\n",
    "        # total steps count\n",
    "        self.total_step = 1\n",
    "\n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        state = torch.FloatTensor(state).to(self.device)\n",
    "        action, dist = self.actor(state)\n",
    "        selected_action = dist.mean if self.is_test else action\n",
    "\n",
    "        if not self.is_test:\n",
    "            value = self.critic(state)\n",
    "            self.states.append(state)\n",
    "            self.actions.append(selected_action)\n",
    "            self.values.append(value)\n",
    "            self.log_probs.append(dist.log_prob(selected_action))\n",
    "\n",
    "        return selected_action.cpu().detach().numpy()\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        next_state = np.reshape(next_state, (1, -1)).astype(np.float64)\n",
    "        reward = np.reshape(reward, (1, -1)).astype(np.float64)\n",
    "        done = np.reshape(done, (1, -1))\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.rewards.append(torch.FloatTensor(reward).to(self.device))\n",
    "            self.masks.append(torch.FloatTensor(1 - done).to(self.device))\n",
    "\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(\n",
    "        self, next_state: np.ndarray\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "\n",
    "        next_state = torch.FloatTensor(next_state).to(device)\n",
    "        next_value = self.critic(next_state)\n",
    "\n",
    "        returns = compute_gae(\n",
    "            next_value,\n",
    "            self.rewards,\n",
    "            self.masks,\n",
    "            self.values,\n",
    "            self.gamma,\n",
    "            self.tau,\n",
    "        )\n",
    "\n",
    "        states = torch.cat(self.states).view(-1, 3)\n",
    "        actions = torch.cat(self.actions)\n",
    "        returns = torch.cat(returns).detach()\n",
    "        values = torch.cat(self.values).detach()\n",
    "        log_probs = torch.cat(self.log_probs).detach()\n",
    "        advantages = returns - values\n",
    "\n",
    "        actor_losses, critic_losses = [], []\n",
    "\n",
    "        for state, action, old_value, old_log_prob, return_, adv in ppo_iter(\n",
    "            epoch=self.epoch,\n",
    "            mini_batch_size=self.batch_size,\n",
    "            states=states,\n",
    "            actions=actions,\n",
    "            values=values,\n",
    "            log_probs=log_probs,\n",
    "            returns=returns,\n",
    "            advantages=advantages,\n",
    "        ):\n",
    "            # calculate ratios\n",
    "            _, dist = self.actor(state)\n",
    "            log_prob = dist.log_prob(action)\n",
    "            ratio = (log_prob - old_log_prob).exp()\n",
    "\n",
    "            # actor_loss\n",
    "            surr_loss = ratio * adv\n",
    "            clipped_surr_loss = (\n",
    "                torch.clamp(ratio, 1.0 - self.epsilon, 1.0 + self.epsilon) * adv\n",
    "            )\n",
    "\n",
    "            # entropy\n",
    "            entropy = dist.entropy().mean()\n",
    "\n",
    "            actor_loss = (\n",
    "                -torch.min(surr_loss, clipped_surr_loss).mean()\n",
    "                - entropy * self.entropy_weight\n",
    "            )\n",
    "\n",
    "            # critic_loss\n",
    "            value = self.critic(state)\n",
    "            #clipped_value = old_value + (value - old_value).clamp(-0.5, 0.5)\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "        \n",
    "            # train critic\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            # train actor\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            actor_losses.append(actor_loss.item())\n",
    "            critic_losses.append(critic_loss.item())\n",
    "\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "        self.values, self.masks, self.log_probs = [], [], []\n",
    "\n",
    "        actor_loss = sum(actor_losses) / len(actor_losses)\n",
    "        critic_loss = sum(critic_losses) / len(critic_losses)\n",
    "\n",
    "        return actor_loss, critic_loss\n",
    "\n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "\n",
    "        state = self.env.reset()\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "\n",
    "        actor_losses, critic_losses = [], []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        while self.total_step <= num_frames + 1:\n",
    "            for _ in range(self.rollout_len):\n",
    "                self.total_step += 1\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done = self.step(action)\n",
    "\n",
    "                state = next_state\n",
    "                score += reward[0][0]\n",
    "\n",
    "                # if episode ends\n",
    "                if done[0][0]:\n",
    "                    state = env.reset()\n",
    "                    state = np.expand_dims(state, axis=0)\n",
    "                    scores.append(score)\n",
    "                    score = 0\n",
    "\n",
    "                    self._plot(\n",
    "                        self.total_step, scores, actor_losses, critic_losses\n",
    "                    )\n",
    "\n",
    "            actor_loss, critic_loss = self.update_model(next_state)\n",
    "            actor_losses.append(actor_loss)\n",
    "            critic_losses.append(critic_loss)\n",
    "\n",
    "        # termination\n",
    "        self.env.close()\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        frames = []\n",
    "        while not done:\n",
    "            frames.append(self.env.render(mode=\"rgb_array\"))\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def _plot(\n",
    "        self,\n",
    "        frame_idx: int,\n",
    "        scores: List[float],\n",
    "        actor_losses: List[float],\n",
    "        critic_losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "\n",
    "        def subplot(loc: int, title: str, values: List[float]):\n",
    "            plt.subplot(loc)\n",
    "            plt.title(title)\n",
    "            plt.plot(values)\n",
    "\n",
    "        subplot_params = [\n",
    "            (131, f\"frame {frame_idx}. score: {np.mean(scores[-10:])}\", scores),\n",
    "            (132, \"actor_loss\", actor_losses),\n",
    "            (133, \"critic_loss\", critic_losses),\n",
    "        ]\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(30, 5))\n",
    "        for loc, title, values in subplot_params:\n",
    "            subplot(loc, title, values)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionNormalizer(gym.ActionWrapper):\n",
    "    \"\"\"Rescale and relocate the actions.\"\"\"\n",
    "\n",
    "    def action(self, action: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Change the range (-1, 1) to (low, high).\"\"\"\n",
    "        low = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        scale_factor = (high - low) / 2\n",
    "        reloc_factor = high - scale_factor\n",
    "\n",
    "        action = action * scale_factor + reloc_factor\n",
    "        action = np.clip(action, low, high)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def reverse_action(self, action: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Change the range (low, high) to (-1, 1).\"\"\"\n",
    "        low = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        scale_factor = (high - low) / 2\n",
    "        reloc_factor = high - scale_factor\n",
    "\n",
    "        action = (action - reloc_factor) / scale_factor\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env_id = \"Pendulum-v1\"\n",
    "env = gym.make(env_id)\n",
    "env = ActionNormalizer(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 100000\n",
    "\n",
    "agent = PPOAgent(\n",
    "    env,\n",
    "    gamma = 0.9,\n",
    "    tau = 0.8,\n",
    "    batch_size = 64,\n",
    "    epsilon = 0.2,\n",
    "    epoch = 64,\n",
    "    rollout_len = 2048,\n",
    "    entropy_weight = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(num_frames, \u001b[39m200\u001b[39;49m)\n",
      "\u001b[1;32m/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_test \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mexpand_dims(state, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m actor_losses, critic_losses \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X14sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m scores \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/shape_base.py:591\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    589\u001b[0m     a \u001b[39m=\u001b[39m asarray(a)\n\u001b[1;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[1;32m    593\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(axis) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    594\u001b[0m     axis \u001b[39m=\u001b[39m (axis,)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "agent.train(num_frames, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m IN_COLAB:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     agent\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mwrappers\u001b[39m.\u001b[39mMonitor(agent\u001b[39m.\u001b[39menv, \u001b[39m\"\u001b[39m\u001b[39mvideos\u001b[39m\u001b[39m\"\u001b[39m, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m frames \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtest()\n",
      "\u001b[1;32m/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=228'>229</a>\u001b[0m     frames\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselect_action(state)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X15sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m     next_state, reward, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gym/core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    328\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gym/core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    328\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gym/wrappers/env_checker.py:53\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_render \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_render \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m env_render_passive_checker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gym/utils/passive_env_checker.py:316\u001b[0m, in \u001b[0;36menv_render_passive_checker\u001b[0;34m(env, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m         \u001b[39massert\u001b[39;00m env\u001b[39m.\u001b[39mrender_mode \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m env\u001b[39m.\u001b[39mrender_mode \u001b[39min\u001b[39;00m render_modes, (\n\u001b[1;32m    312\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe environment was initialized successfully however with an unsupported render mode. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRender mode: \u001b[39m\u001b[39m{\u001b[39;00menv\u001b[39m.\u001b[39mrender_mode\u001b[39m}\u001b[39;00m\u001b[39m, modes: \u001b[39m\u001b[39m{\u001b[39;00mrender_modes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         )\n\u001b[0;32m--> 316\u001b[0m result \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    318\u001b[0m \u001b[39m# TODO: Check that the result is correct\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "# test\n",
    "if IN_COLAB:\n",
    "    agent.env = gym.wrappers.Monitor(agent.env, \"videos\", force=True)\n",
    "frames = agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'JSAnimation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# for jupyter\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m animation\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mJSAnimation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mIPython_display\u001b[39;00m \u001b[39mimport\u001b[39;00m display_animation\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeltomadakis/Documents/DataScienceProjectRepo/MichaelTutorialCopy/pendulum.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mdisplay_frames_as_gif\u001b[39m(frames):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'JSAnimation'"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:  # for colab\n",
    "    import base64\n",
    "    import glob\n",
    "    import io\n",
    "    import os\n",
    "\n",
    "    from IPython.display import HTML, display\n",
    "\n",
    "    def ipython_show_video(path: str) -> None:\n",
    "        \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "        if not os.path.isfile(path):\n",
    "            raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "        video = io.open(path, \"r+b\").read()\n",
    "        encoded = base64.b64encode(video)\n",
    "\n",
    "        display(HTML(\n",
    "            data=\"\"\"\n",
    "            <video alt=\"test\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "            </video>\n",
    "            \"\"\".format(encoded.decode(\"ascii\"))\n",
    "        ))\n",
    "\n",
    "    list_of_files = glob.glob(\"videos/*.mp4\")\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(latest_file)\n",
    "    ipython_show_video(latest_file)\n",
    "\n",
    "else:  # for jupyter\n",
    "    from matplotlib import animation\n",
    "    from JSAnimation.IPython_display import display_animation\n",
    "    from IPython.display import display\n",
    "\n",
    "\n",
    "    def display_frames_as_gif(frames):\n",
    "        \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
    "        patch = plt.imshow(frames[0])\n",
    "        plt.axis('off')\n",
    "\n",
    "        def animate(i):\n",
    "            patch.set_data(frames[i])\n",
    "\n",
    "        anim = animation.FuncAnimation(\n",
    "            plt.gcf(), animate, frames = len(frames), interval=50\n",
    "        )\n",
    "        display(display_animation(anim, default_mode='loop'))\n",
    "\n",
    "\n",
    "    # display \n",
    "    display_frames_as_gif(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
